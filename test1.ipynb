{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec986ce-dade-4f5d-868c-9b0dd765cdfe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### James Butcher - 5-18-25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133b347-5f11-4be6-b125-26880bcec7a6",
   "metadata": {},
   "source": [
    "A basic test setup for LangGraph using Python and Ollama running locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088343c-4208-4472-914d-2d62be591589",
   "metadata": {},
   "source": [
    "## Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa01446-a367-47ab-bb08-35ad190f6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd918f-1e6d-41e8-adba-a3bb41b8e688",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca7c202-b907-4b5b-a113-eded8c675399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model_path = os.path.expanduser(\n",
    "    \"~/.cache/lm-studio/models/lmstudio-community/\"\n",
    "    \"Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\"\n",
    ")\n",
    "\n",
    "\"\"\" API Docs: \n",
    "https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html\n",
    "\"\"\"\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    model_path=model_path,\n",
    "    chat_format=\"chatml\", # Works with most models\n",
    "    temperature=1.0,  # Controlds the randomness/creativity [0.0 - 2.0]\n",
    "    num_predict=64,  # Max number of tokens\n",
    "    #n_ctx=2048, # Context length - default: 2048 (others are 512, 1024, 4096)\n",
    "    #n_threads=4, # Number of threads to use for inference (default is 4)\n",
    "    #num_predict=128  # Maximum number of tokens to predict when generating text. (Default: 128, -1 = infinite generation, -2 = fill context)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca056c-42df-44e4-83e4-48413a5f9cd6",
   "metadata": {},
   "source": [
    "## Types and Fields imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27ea774-1658-4fca-bb02-c1771fd8bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ca3ec-75f7-4c84-b8ea-f3e6f714d9aa",
   "metadata": {},
   "source": [
    "## LangGraph Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060d0254-d58d-4f53-9b8a-e4f29f7f7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END  # For building the graph\n",
    "from langgraph.graph.message import add_messages    # For defining states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d7e59-7e6a-4933-9b32-ac62e661a19f",
   "metadata": {},
   "source": [
    "## Define States\n",
    "\n",
    "Define the structure of the \"States\" to be used by the graph\n",
    "The below definition forces states to be of this form:\n",
    "```\n",
    "{ \n",
    "    \"messages\": [ <messages list> ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c77e5d-5a87-45fb-8f86-3d7885c4d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b546518-ba74-4f59-9ab5-06fce74d4735",
   "metadata": {},
   "source": [
    "## Define Nodes (Actions)\n",
    "\n",
    "Define a node by creating a function that takes a state and returns a modified state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15404c4b-fbb7-4c64-a9a4-b4f2253d000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    # Take all the messages from the previous state and pass it to the LLM.\n",
    "    # Then set the new set of messages to the response.\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbccc06-77a5-435e-b7ae-affbafa90d2f",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44100a97-84b3-4c73-bcde-da95279b4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c68e83-6710-4306-a50d-27345d697eb0",
   "metadata": {},
   "source": [
    "#### Add all the nodes defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04fb6b4e-825b-47d6-af93-5014c7c8a90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1dd4df5a9c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "# ... add more here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b14056-cb0e-46cb-acbf-91b5eaea43db",
   "metadata": {},
   "source": [
    "#### Connect all the nodes\n",
    "- All graphs require a start and end node.\n",
    "```\n",
    "  START\n",
    "    |\n",
    "   \\|/\n",
    "[chatbot]\n",
    "    |\n",
    "   \\|/\n",
    "   END\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645ca8f4-f2ab-4a77-b785-2fa3a7292fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1dd4df5a9c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87cbb9-81b8-4930-a27a-83bcdbb0f9ba",
   "metadata": {},
   "source": [
    "#### Compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff21584-c4c1-49b8-8def-3344dbb3c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a352127-805f-4783-8845-eb8a7d8d3030",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52492e91-9ab2-4f99-bace-1367596bfa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a message:  Write a bad poem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:Here's a terrible poem:\n",
      "\n",
      "Rhubarb is red and squishy too\n",
      "It's good for jam or so I chew\n",
      "Pineapple pizza is the best\n",
      "I like it on my shirt, it passes the test\n",
      "\n",
      "My dog's name is Fluffy McFlufferson\n",
      "He chases his tail\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"\\nEnter a message: \")\n",
    "\n",
    "starting_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": user_input\n",
    "}\n",
    "state = graph.invoke({\"messages\": [starting_message]})\n",
    "\n",
    "print(\"\\nOutput:\" + state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200784c7-c501-46f5-992e-a91145c232fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a2d12-fa76-4322-a5ea-08133cf979a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
